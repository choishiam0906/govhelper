# ì§€ìì²´ ê³µê³  ìŠ¤í¬ë˜í¼ êµ¬í˜„ ê°€ì´ë“œ

## ê°œìš”

ì§€ìì²´(ê´‘ì—­ì‹œ/ë„) ì •ë¶€ì§€ì›ì‚¬ì—… ê³µê³ ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ëŠ” ìŠ¤í¬ë˜í¼ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

---

## í˜„ì¬ êµ¬í˜„ ìƒíƒœ

### âœ… êµ¬í˜„ ì™„ë£Œ

| ì§€ìì²´ | ìŠ¤í¬ë˜í¼ íŒŒì¼ | í™œì„±í™” | ë°ì´í„° ì†ŒìŠ¤ ìƒíƒœ |
|--------|--------------|--------|-----------------|
| ì„œìš¸íŠ¹ë³„ì‹œ | `seoul.ts` | âœ… | ğŸ”§ êµ¬ì¡°ë§Œ êµ¬ì¶• (ì‹¤ì œ API í•„ìš”) |
| ê²½ê¸°ë„ | `gyeonggi.ts` | âœ… | ğŸ”§ êµ¬ì¡°ë§Œ êµ¬ì¶• (ì‹¤ì œ API í•„ìš”) |

### ğŸ“‹ êµ¬í˜„ ëŒ€ê¸°

ë‚˜ë¨¸ì§€ 15ê°œ ê´‘ì—­ì‹œ/ë„:
- ë¶€ì‚°, ëŒ€êµ¬, ì¸ì²œ, ê´‘ì£¼, ëŒ€ì „, ìš¸ì‚°, ì„¸ì¢…
- ê°•ì›, ì¶©ë¶, ì¶©ë‚¨, ì „ë¶, ì „ë‚¨, ê²½ë¶, ê²½ë‚¨, ì œì£¼

---

## ì•„í‚¤í…ì²˜

```
í™œì„±í™”ëœ ì§€ìì²´ ì†ŒìŠ¤
    â†“
ìŠ¤í¬ë˜í¼ ì‹¤í–‰ (API/RSS/HTML)
    â†“
í‘œì¤€ í¬ë§· ë³€í™˜ (ScraperAnnouncement)
    â†“
ì¤‘ë³µ ê°ì§€ (ì œëª© ê¸°ë°˜)
    â†“
DB ì €ì¥ (announcements í…Œì´ë¸”)
    â†“
AI ìë™ ë¶„ë¥˜ (eligibility_criteria)
```

---

## íŒŒì¼ êµ¬ì¡°

```
lib/announcements/scrapers/
â”œâ”€â”€ types.ts           # íƒ€ì… ì •ì˜
â”œâ”€â”€ index.ts           # ìŠ¤í¬ë˜í¼ ë ˆì§€ìŠ¤íŠ¸ë¦¬
â”œâ”€â”€ seoul.ts           # ì„œìš¸ì‹œ ìŠ¤í¬ë˜í¼
â”œâ”€â”€ gyeonggi.ts        # ê²½ê¸°ë„ ìŠ¤í¬ë˜í¼
â””â”€â”€ README.md          # ì´ íŒŒì¼
```

---

## ìŠ¤í¬ë˜í¼ êµ¬í˜„ ë°©ë²•

### 1ë‹¨ê³„: ìƒˆ ìŠ¤í¬ë˜í¼ íŒŒì¼ ìƒì„±

`lib/announcements/scrapers/busan.ts` (ì˜ˆì‹œ: ë¶€ì‚°ì‹œ)

```typescript
import * as cheerio from 'cheerio'
import { ScraperResult, ScraperOptions, ScraperAnnouncement } from './types'

export class BusanScraper {
  readonly id = 'busan'
  readonly name = 'ë¶€ì‚°ê´‘ì—­ì‹œ'

  private readonly BASE_URL = 'https://www.busan.go.kr'

  async scrape(options?: ScraperOptions): Promise<ScraperResult> {
    const limit = options?.limit || 20

    try {
      // TODO: ì‹¤ì œ API í˜¸ì¶œ ë˜ëŠ” ì›¹ ìŠ¤í¬ë˜í•‘ ë¡œì§
      const announcements = await this.fetchAnnouncements(limit)

      return {
        announcements,
        total: announcements.length,
        source: 'local_busan',
      }

    } catch (error) {
      console.error('[ë¶€ì‚°ì‹œ ìŠ¤í¬ë˜í¼] ì˜¤ë¥˜:', error)
      return {
        announcements: [],
        total: 0,
        source: 'local_busan',
      }
    }
  }

  private async fetchAnnouncements(limit: number): Promise<ScraperAnnouncement[]> {
    // êµ¬í˜„ ë°©ë²• ì„ íƒ:
    // 1. ê³µê³µë°ì´í„° API
    // 2. RSS í”¼ë“œ
    // 3. HTML ìŠ¤í¬ë˜í•‘

    return []
  }
}

export const busanScraper = new BusanScraper()
```

### 2ë‹¨ê³„: ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡

`lib/announcements/scrapers/index.ts` ìˆ˜ì •:

```typescript
import { busanScraper } from './busan'

export const scrapers: Record<string, LocalScraper> = {
  seoul: seoulScraper,
  gyeonggi: gyeonggiScraper,
  busan: busanScraper,  // ì¶”ê°€
  // ...
}
```

### 3ë‹¨ê³„: ì§€ìì²´ ì†ŒìŠ¤ í™œì„±í™”

`lib/announcements/local-sources.ts` ìˆ˜ì •:

```typescript
{
  id: 'busan',
  name: 'ë¶€ì‚°ê´‘ì—­ì‹œ',
  url: 'https://www.busan.go.kr',
  enabled: true,  // false â†’ true
  description: 'ë¶€ì‚°ì‹œ ì¤‘ì†Œê¸°ì—… ë° ìŠ¤íƒ€íŠ¸ì—… ì§€ì›ì‚¬ì—…'
}
```

### 4ë‹¨ê³„: ë™ê¸°í™” API ìë™ ì—°ë™

ë™ê¸°í™” API (`app/api/announcements/local/sync/route.ts`)ê°€ ìë™ìœ¼ë¡œ ìƒˆ ìŠ¤í¬ë˜í¼ë¥¼ ì¸ì‹í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.

---

## ë°ì´í„° ì†ŒìŠ¤ ìˆ˜ì§‘ ë°©ë²•

### ë°©ë²• 1: ê³µê³µë°ì´í„° API (ê¶Œì¥)

**ì¥ì :**
- ì•ˆì •ì ì¸ ë°ì´í„° ì œê³µ
- êµ¬ì¡°í™”ëœ JSON ì‘ë‹µ
- ë³€ê²½ì— ê°•í•¨

**ì˜ˆì‹œ:**
```typescript
private async fetchFromApi(limit: number): Promise<ScraperAnnouncement[]> {
  const apiKey = process.env.BUSAN_DATA_API_KEY
  const url = `https://openapi.busan.go.kr/api/support?key=${apiKey}&limit=${limit}`

  const response = await fetch(url)
  const data = await response.json()

  return data.items.map(item => ({
    source_id: item.id,
    title: item.title,
    organization: 'ë¶€ì‚°ê´‘ì—­ì‹œ',
    application_end: item.deadline,
    detail_url: item.url,
  }))
}
```

**í™˜ê²½ë³€ìˆ˜ ì¶”ê°€:**
`.env.local`ì— API í‚¤ ì¶”ê°€:
```bash
BUSAN_DATA_API_KEY=ë°œê¸‰ë°›ì€_API_í‚¤
```

### ë°©ë²• 2: RSS í”¼ë“œ

**ì¥ì :**
- ê°„ë‹¨í•œ êµ¬í˜„
- ë³„ë„ API í‚¤ ë¶ˆí•„ìš”
- ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸

**ì˜ˆì‹œ:**
```typescript
// rss-parser ì„¤ì¹˜ í•„ìš”: npm install rss-parser
import Parser from 'rss-parser'

private async fetchFromRss(limit: number): Promise<ScraperAnnouncement[]> {
  const parser = new Parser()
  const feed = await parser.parseURL('https://www.busan.go.kr/rss/support.xml')

  return feed.items.slice(0, limit).map(item => ({
    source_id: item.guid || item.link,
    title: item.title,
    organization: 'ë¶€ì‚°ê´‘ì—­ì‹œ',
    content: item.contentSnippet,
    detail_url: item.link,
    application_end: this.parseDate(item.pubDate),
  }))
}
```

### ë°©ë²• 3: HTML ìŠ¤í¬ë˜í•‘ (ìµœí›„ ìˆ˜ë‹¨)

**ì£¼ì˜ì‚¬í•­:**
- ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ ì‹œ ìŠ¤í¬ë˜í¼ ìˆ˜ì • í•„ìš”
- robots.txt í™•ì¸ í•„ìˆ˜
- ìš”ì²­ ê°„ê²© 1ì´ˆ ì´ìƒ ìœ ì§€
- User-Agent í—¤ë” ëª…ì‹œ

**ì˜ˆì‹œ:**
```typescript
private async fetchFromWeb(limit: number): Promise<ScraperAnnouncement[]> {
  const url = 'https://www.busan.go.kr/support/list'

  const response = await fetch(url, {
    headers: {
      'User-Agent': 'Mozilla/5.0 (compatible; GovHelper/1.0)',
    },
  })

  const html = await response.text()
  const $ = cheerio.load(html)

  const announcements: ScraperAnnouncement[] = []

  $('.notice-list .item').each((index, element) => {
    if (index >= limit) return false

    const $el = $(element)

    announcements.push({
      source_id: `BUSAN_${Date.now()}_${index}`,
      title: $el.find('.title').text().trim(),
      organization: 'ë¶€ì‚°ê´‘ì—­ì‹œ',
      detail_url: this.buildUrl($el.find('a').attr('href')),
      application_end: this.parseDate($el.find('.date').text()),
    })
  })

  return announcements
}
```

---

## í‘œì¤€ ë°ì´í„° í¬ë§·

ìŠ¤í¬ë˜í¼ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤:

```typescript
interface ScraperAnnouncement {
  source_id: string              // í•„ìˆ˜: ì›ë³¸ ID (ê³ ìœ ê°’)
  title: string                  // í•„ìˆ˜: ê³µê³  ì œëª©
  organization: string           // í•„ìˆ˜: ì§€ì› ê¸°ê´€ëª…

  category?: string              // ì„ íƒ: ë¶„ë¥˜ (ê¸°ë³¸: 'ì§€ìì²´')
  support_type?: string          // ì„ íƒ: ì§€ì› ìœ í˜• (ê¸°ë³¸: ì§€ìì²´ëª…)
  target_company?: string        // ì„ íƒ: ëŒ€ìƒ ê¸°ì—…
  support_amount?: string        // ì„ íƒ: ì§€ì› ê¸ˆì•¡
  application_start?: string     // ì„ íƒ: ì ‘ìˆ˜ ì‹œì‘ì¼ (YYYY-MM-DD)
  application_end?: string       // ì„ íƒ: ì ‘ìˆ˜ ë§ˆê°ì¼ (YYYY-MM-DD)
  content?: string               // ì„ íƒ: ê³µê³  ë‚´ìš©
  detail_url?: string            // ì„ íƒ: ìƒì„¸ë³´ê¸° URL
  attachment_urls?: string[]     // ì„ íƒ: ì²¨ë¶€íŒŒì¼ URL ëª©ë¡
}
```

---

## source í•„ë“œ ëª…ëª… ê·œì¹™

ê° ì§€ìì²´ì˜ `source` í•„ë“œëŠ” ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¦…ë‹ˆë‹¤:

```
local_{ì§€ìì²´ID}
```

| ì§€ìì²´ | source í•„ë“œ |
|--------|------------|
| ì„œìš¸ì‹œ | `local_seoul` |
| ê²½ê¸°ë„ | `local_gyeonggi` |
| ë¶€ì‚°ì‹œ | `local_busan` |
| ëŒ€êµ¬ì‹œ | `local_daegu` |
| ... | ... |

---

## ì¤‘ë³µ ê°ì§€

ë™ê¸°í™” APIê°€ ìë™ìœ¼ë¡œ ì¤‘ë³µì„ ê°ì§€í•©ë‹ˆë‹¤:

1. **ì œëª© ì •ê·œí™”**: ì—°ë„/ì°¨ìˆ˜ ì œê±°, íŠ¹ìˆ˜ë¬¸ì ì œê±°
2. **ì •í™• ë§¤ì¹­**: ì •ê·œí™” í›„ ì œëª©ì´ ë™ì¼í•˜ë©´ ì¤‘ë³µ
3. **ìœ ì‚¬ë„ ë§¤ì¹­**: Levenshtein ê±°ë¦¬ 90% ì´ìƒì´ë©´ ì¤‘ë³µ

ì¤‘ë³µìœ¼ë¡œ íŒë‹¨ë˜ë©´ DBì— ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

---

## AI ìë™ ë¶„ë¥˜

ë™ê¸°í™” í›„ ìµœì‹  10ê°œ ê³µê³ ì— ëŒ€í•´ AIê°€ ìë™ìœ¼ë¡œ ì§€ì›ìê²©ì„ íŒŒì‹±í•©ë‹ˆë‹¤:

- ê¸°ì—…ìœ í˜• (ì¤‘ì†Œê¸°ì—…, ìŠ¤íƒ€íŠ¸ì—… ë“±)
- ì§ì›ìˆ˜ ë²”ìœ„
- ë§¤ì¶œ ë²”ìœ„
- ì—…ë ¥ ì¡°ê±´
- ì—…ì¢…/ì§€ì—­ ì œí•œ
- í•„ìš” ì¸ì¦ (ë²¤ì²˜, ì´ë…¸ë¹„ì¦ˆ ë“±)

íŒŒì‹± ê²°ê³¼ëŠ” `announcements.eligibility_criteria` (JSONB) ì»¬ëŸ¼ì— ì €ì¥ë©ë‹ˆë‹¤.

---

## í…ŒìŠ¤íŠ¸

### ìˆ˜ë™ íŠ¸ë¦¬ê±°

```bash
# ë¡œì»¬ ê°œë°œ í™˜ê²½
curl -X POST http://localhost:3000/api/announcements/local/sync

# í”„ë¡œë•ì…˜
curl -X POST https://govhelpers.com/api/announcements/local/sync
```

### Cron ìŠ¤ì¼€ì¤„

`vercel.json`:
```json
{
  "path": "/api/announcements/local/sync",
  "schedule": "0 4 * * *"  // ë§¤ì¼ 04:00 UTC (13:00 KST)
}
```

### ë™ê¸°í™” ë¡œê·¸ í™•ì¸

ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸:
- URL: `/admin`
- ì†ŒìŠ¤: `local`

ë˜ëŠ” APIë¡œ í™•ì¸:
```bash
curl https://govhelpers.com/api/admin/sync-status?source=local
```

---

## ì—ëŸ¬ ì²˜ë¦¬

ìŠ¤í¬ë˜í¼ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤:

```typescript
async scrape(options?: ScraperOptions): Promise<ScraperResult> {
  try {
    const announcements = await this.fetchAnnouncements()
    return {
      announcements,
      total: announcements.length,
      source: 'local_busan',
    }
  } catch (error) {
    console.error('[ë¶€ì‚°ì‹œ ìŠ¤í¬ë˜í¼] ì˜¤ë¥˜:', error)
    // ë¹ˆ ê²°ê³¼ ë°˜í™˜ (ë‹¤ë¥¸ ì§€ìì²´ëŠ” ê³„ì† ì§„í–‰)
    return {
      announcements: [],
      total: 0,
      source: 'local_busan',
    }
  }
}
```

ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ì „ì²´ ë™ê¸°í™”ëŠ” ê³„ì† ì§„í–‰ë©ë‹ˆë‹¤.

---

## ë‚ ì§œ íŒŒì‹± ìœ í‹¸ë¦¬í‹°

ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ì„ YYYY-MM-DDë¡œ ë³€í™˜:

```typescript
private parseDate(dateStr: string): string | undefined {
  if (!dateStr) return undefined

  // "2026-01-28"
  if (/^\d{4}-\d{2}-\d{2}$/.test(dateStr)) {
    return dateStr
  }

  // "2026.01.28"
  if (/^\d{4}\.\d{2}\.\d{2}$/.test(dateStr)) {
    return dateStr.replace(/\./g, '-')
  }

  // "20260128"
  if (/^\d{8}$/.test(dateStr)) {
    return `${dateStr.slice(0, 4)}-${dateStr.slice(4, 6)}-${dateStr.slice(6, 8)}`
  }

  // "~ 2026.01.28" (ë§ˆê°ì¼ë§Œ ì¶”ì¶œ)
  const match = dateStr.match(/~\s*(\d{4})[.\-\/](\d{2})[.\-\/](\d{2})/)
  if (match) {
    return `${match[1]}-${match[2]}-${match[3]}`
  }

  return undefined
}
```

---

## ì°¸ê³  ìë£Œ

### ê³µê³µë°ì´í„° í¬í„¸
- https://www.data.go.kr
- ê²€ìƒ‰ í‚¤ì›Œë“œ: "ì¤‘ì†Œê¸°ì—…", "ì†Œìƒê³µì¸", "ì°½ì—…", "ì§€ì›ì‚¬ì—…"

### ì§€ìì²´ ê³µì‹ ì‚¬ì´íŠ¸
| ì§€ìì²´ | URL |
|--------|-----|
| ì„œìš¸ì‹œ | https://www.seoul.go.kr |
| ê²½ê¸°ë„ | https://www.gg.go.kr |
| ë¶€ì‚°ì‹œ | https://www.busan.go.kr |
| ëŒ€êµ¬ì‹œ | https://www.daegu.go.kr |

### ê¸°ìˆ  ìŠ¤íƒ
- **cheerio**: HTML íŒŒì‹± (ì„¤ì¹˜ë¨)
- **rss-parser**: RSS í”¼ë“œ íŒŒì‹± (ë¯¸ì„¤ì¹˜, í•„ìš” ì‹œ ì¶”ê°€)
- **node-fetch**: HTTP ìš”ì²­ (Next.js ë‚´ì¥)

---

## ì‘ì„±ì

- ì‘ì„±ì¼: 2026-01-28
- ì‘ì„±ì: Claude (Sisyphus-Junior)
- ë²„ì „: 1.0.0
